{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from imblearn.datasets import make_imbalance\n",
    "\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the dataset\n",
    "# multiplier = 1.0\n",
    "# desiredtotal = 100000\n",
    "# nsamp = int(np.round(2*desiredtotal/(1+multiplier)))\n",
    "# Xfull, yfull = make_moons(n_samples=nsamp, shuffle=True, noise=0.05, random_state=10)\n",
    "Xdat, ydat = load_breast_cancer(return_X_y=True)\n",
    "\n",
    "\n",
    "# def ratio_func(y, multiplier, minority_class):\n",
    "#     target_stats = Counter(y)\n",
    "#     return {minority_class: int(multiplier * target_stats[minority_class])}\n",
    "\n",
    "\n",
    "\n",
    "# Xdat, ydat = make_imbalance(Xfull, yfull, sampling_strategy=ratio_func,\n",
    "#                             **{\"multiplier\": multiplier,\n",
    "#                                \"minority_class\": 1})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "[357 212]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(ydat))\n",
    "print(np.array([np.sum(ydat==1), np.sum(ydat==0)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 31)\n"
     ]
    }
   ],
   "source": [
    "alldat = np.hstack([Xdat, np.expand_dims(ydat, axis=1)])\n",
    "np.random.shuffle(alldat)\n",
    "print(alldat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xavier_init(size):\n",
    "    in_dim = size[0]\n",
    "    xavier_stddev = 1. / tf.sqrt(in_dim / 2.)\n",
    "    return tf.random_normal(shape=size, stddev=xavier_stddev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/hbhat/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None, 31])\n",
    "\n",
    "Dnn = 8\n",
    "\n",
    "D_W1 = tf.Variable(xavier_init([31, Dnn]))\n",
    "D_b1 = tf.Variable(tf.zeros(shape=[Dnn]))\n",
    "\n",
    "D_W2 = tf.Variable(xavier_init([Dnn, Dnn]))\n",
    "D_b2 = tf.Variable(tf.zeros(shape=[Dnn]))\n",
    "\n",
    "D_W3 = tf.Variable(xavier_init([Dnn, 1]))\n",
    "D_b3 = tf.Variable(tf.zeros(shape=[1]))\n",
    "\n",
    "theta_D = [D_W1, D_W2, D_W3, D_b1, D_b2, D_b3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_dim = 50\n",
    "Z = tf.placeholder(tf.float32, shape=[None, Z_dim])\n",
    "\n",
    "Gnn = 8\n",
    "\n",
    "G_W1 = tf.Variable(xavier_init([Z_dim, Gnn]))\n",
    "G_b1 = tf.Variable(tf.zeros(shape=[Gnn]))\n",
    "\n",
    "G_W2 = tf.Variable(xavier_init([Gnn, Gnn]))\n",
    "G_b2 = tf.Variable(tf.zeros(shape=[Gnn]))\n",
    "\n",
    "G_W3 = tf.Variable(xavier_init([Gnn, 31]))\n",
    "G_b3 = tf.Variable(tf.zeros(shape=[31]))\n",
    "\n",
    "theta_G = [G_W1, G_W2, G_W3, G_b1, G_b2, G_b3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_Z(m, n):\n",
    "    return np.random.uniform(-1., 1., size=[m, n])\n",
    "\n",
    "\n",
    "def generator(z):\n",
    "    G_h1 = tf.nn.relu(tf.matmul(z, G_W1) + G_b1)\n",
    "    G_h2 = tf.nn.relu(tf.matmul(G_h1, G_W2) + G_b2)\n",
    "    G_h3 = tf.matmul(G_h2, G_W3) + G_b3\n",
    "    return G_h3\n",
    "\n",
    "\n",
    "def discriminator(x):\n",
    "    D_h1 = tf.nn.relu(tf.matmul(x, D_W1) + D_b1)\n",
    "    D_h2 = tf.nn.relu(tf.matmul(D_h1, D_W2) + D_b2)\n",
    "    D_logit = tf.matmul(D_h2, D_W3) + D_b3\n",
    "    D_prob = tf.nn.sigmoid(D_logit)\n",
    "\n",
    "    return D_prob, D_logit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_sample = generator(Z)\n",
    "D_real, D_logit_real = discriminator(X)\n",
    "D_fake, D_logit_fake = discriminator(G_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_real, labels=tf.ones_like(D_logit_real)))\n",
    "D_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_fake, labels=tf.zeros_like(D_logit_fake)))\n",
    "D_loss = D_loss_real + D_loss_fake\n",
    "G_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_fake, labels=tf.ones_like(D_logit_fake)))\n",
    "\n",
    "D_solver = tf.train.AdamOptimizer(learning_rate=0.000001).minimize(D_loss, var_list=theta_D)\n",
    "G_solver = tf.train.AdamOptimizer(learning_rate=0.000001).minimize(G_loss, var_list=theta_G)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0\n",
      "D loss: 1.013\n",
      "G_loss: 0.5074\n",
      "\n",
      "Iter: 1000\n",
      "D loss: 0.9841\n",
      "G_loss: 0.5399\n",
      "\n",
      "Iter: 2000\n",
      "D loss: 0.9938\n",
      "G_loss: 0.5622\n",
      "\n",
      "Iter: 3000\n",
      "D loss: 0.9955\n",
      "G_loss: 0.4957\n",
      "\n",
      "Iter: 4000\n",
      "D loss: 0.9976\n",
      "G_loss: 0.4654\n",
      "\n",
      "Iter: 5000\n",
      "D loss: 0.9331\n",
      "G_loss: 0.5292\n",
      "\n",
      "Iter: 6000\n",
      "D loss: 1.072\n",
      "G_loss: 0.5373\n",
      "\n",
      "Iter: 7000\n",
      "D loss: 1.009\n",
      "G_loss: 0.5317\n",
      "\n",
      "Iter: 8000\n",
      "D loss: 1.076\n",
      "G_loss: 0.4991\n",
      "\n",
      "Iter: 9000\n",
      "D loss: 0.9063\n",
      "G_loss: 0.5365\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "mb_size = 100\n",
    "adr = alldat.shape[0]\n",
    "\n",
    "i = 0\n",
    "\n",
    "for it in range(10000):\n",
    "    eit = it % (adr // mb_size)\n",
    "    si = eit * mb_size\n",
    "    ei = (eit+1) * mb_size\n",
    "    X_mb = alldat[si:ei, :]\n",
    "\n",
    "    _, D_loss_curr = sess.run([D_solver, D_loss], feed_dict={X: X_mb, Z: sample_Z(mb_size, Z_dim)})\n",
    "    _, G_loss_curr = sess.run([G_solver, G_loss], feed_dict={Z: sample_Z(mb_size, Z_dim)})\n",
    "\n",
    "    if it % 1000 == 0:\n",
    "        print('Iter: {}'.format(it))\n",
    "        print('D loss: {:.4}'. format(D_loss_curr))\n",
    "        print('G_loss: {:.4}'.format(G_loss_curr))\n",
    "        print()\n",
    "    \n",
    "    if it % 1000 == 0:\n",
    "        testraw = sess.run(G_sample, feed_dict={Z: sample_Z(1000, Z_dim)})\n",
    "        test = TSNE(n_components=2).fit_transform(testraw[:,:30])\n",
    "        testc = np.array(np.round(testraw[:,30]),dtype='int32')\n",
    "        fig = plt.figure(figsize=(4, 4))\n",
    "        plt.scatter(test[testc == 0, 0], test[testc == 0, 1], label=\"Class #0\", alpha=0.5, s=0.01)\n",
    "        plt.scatter(test[testc != 0, 0], test[testc != 0, 1], label=\"Class #1\", alpha=0.5, s=0.01)\n",
    "        plt.savefig('out/{}.png'.format(str(i).zfill(3)), bbox_inches='tight')\n",
    "        i += 1\n",
    "        plt.close(fig)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Xfull' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-1da61173f26a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXfull\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0myfull\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXfull\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0myfull\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Class #0\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXfull\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0myfull\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXfull\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0myfull\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Class #1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# ax.scatter(X_[y_ == 1, 0], X_[y_ == 1, 1], label=\"Class #1\", alpha=0.5)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Xfull' is not defined"
     ]
    }
   ],
   "source": [
    "# plt.scatter(Xfull[yfull == 0, 0], Xfull[yfull == 0, 1], label=\"Class #0\", alpha=0.5, s=0.01)\n",
    "# plt.scatter(Xfull[yfull == 1, 0], Xfull[yfull == 1, 1], label=\"Class #1\", alpha=0.5, s=0.01)\n",
    "# plt.show()\n",
    "# # ax.scatter(X_[y_ == 1, 0], X_[y_ == 1, 1], label=\"Class #1\", alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = sess.run(G_sample, feed_dict={Z: sample_Z(900000, Z_dim)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1  0  1  2]\n",
      "789132\n",
      "110868\n"
     ]
    }
   ],
   "source": [
    "testc = np.array(np.round(test[:,30]),dtype='int32')\n",
    "print(np.unique(testc))\n",
    "print(np.sum(testc==0))\n",
    "print(np.sum(testc!=0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(test[testc == 0, 0], test[testc == 0, 1], label=\"Class #0\", alpha=0.5)\n",
    "plt.scatter(test[testc == 1, 0], test[testc == 1, 1], label=\"Class #1\", alpha=0.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[:,2] = testc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdat = np.vstack([alldat, test[testc==1,:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array([np.sum(newdat[:,2]==1), np.sum(newdat[:,2]==0)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(newdat[newdat[:,2] == 0, 0], newdat[newdat[:,2] == 0, 1], label=\"Class #0\", alpha=0.5)\n",
    "plt.scatter(newdat[newdat[:,2] == 1, 0], newdat[newdat[:,2] == 1, 1], label=\"Class #1\", alpha=0.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
